{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645bbe8b-8a09-4b2d-9264-aa231759b35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn import set_config\n",
    "set_config(transform_output=\"pandas\")\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 4)\n",
    "sns.set_context(\"talk\", font_scale=0.9)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6ccda0-6001-43f9-8bc5-a69f1c4fb076",
   "metadata": {},
   "outputs": [],
   "source": [
    "â€‹def regression_metrics(y_true, y_pred, label='', verbose = True, output_dict=False):\n",
    "  # Get metrics\n",
    "  mae = mean_absolute_error(y_true, y_pred)\n",
    "  mse = mean_squared_error(y_true, y_pred)\n",
    "  rmse = mean_squared_error(y_true, y_pred, squared=False) \n",
    "  r_squared = r2_score(y_true, y_pred)\n",
    "  if verbose == True:\n",
    "    # Print Result with Label and Header\n",
    "    header = \"-\"*60\n",
    "    print(header, f\"Regression Metrics: {label}\", header, sep='\\n')\n",
    "    print(f\"- MAE = {mae:,.3f}\")\n",
    "    print(f\"- MSE = {mse:,.3f}\")\n",
    "    print(f\"- RMSE = {rmse:,.3f}\")\n",
    "    print(f\"- R^2 = {r_squared:,.3f}\")\n",
    "  if output_dict == True:\n",
    "      metrics = {'Label':label, 'MAE':mae,\n",
    "                 'MSE':mse, 'RMSE':rmse, 'R^2':r_squared}\n",
    "      return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419e94d9-ab15-4b8b-841d-116fd3769547",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_regression(reg, X_train, y_train, X_test, y_test, verbose = True,\n",
    "                        output_frame=False):\n",
    "  # Get predictions for training data\n",
    "  y_train_pred = reg.predict(X_train)\n",
    " \n",
    "  # Call the helper function to obtain regression metrics for training data\n",
    "  results_train = regression_metrics(y_train, y_train_pred, verbose = verbose,\n",
    "                                     output_dict=output_frame,\n",
    "                                     label='Training Data')\n",
    "  print()\n",
    "  # Get predictions for test data\n",
    "  y_test_pred = reg.predict(X_test)\n",
    "  # Call the helper function to obtain regression metrics for test data\n",
    "  results_test = regression_metrics(y_test, y_test_pred, verbose = verbose,\n",
    "                                  output_dict=output_frame,\n",
    "                                    label='Test Data' )\n",
    "  \n",
    "  # Store results in a dataframe if ouput_frame is True\n",
    "  if output_frame:\n",
    "    results_df = pd.DataFrame([results_train,results_test])\n",
    "    # Set the label as the index \n",
    "    results_df = results_df.set_index('Label')\n",
    "    # Set index.name to none to get a cleaner looking result\n",
    "    results_df.index.name=None\n",
    "    # Return the dataframe\n",
    "    return results_df.round(3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360c7aa7-f3c3-4b8a-b927-9be9092e5417",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import statsmodels base api module for the data\n",
    "import statsmodels.api as sm\n",
    "co2_data = sm.datasets.co2.load_pandas()\n",
    "df = co2_data.data\n",
    "df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c372659-b077-4750-b6ff-4e60b67d0842",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the data\n",
    "ax = df.plot()\n",
    "ax.set(ylabel=\"CO2 (PPM)\", xlabel=\"Week\", title=\"CO2 Levels Over Time\");\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ceb9e70-f0a0-40bd-9a80-531aeafb2d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for null values\n",
    "df.isna().sum()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88da2e3-03d3-42f7-9c6f-c812637d1850",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute null values\n",
    "df = df.interpolate()\n",
    "df.isna().sum()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca85a73-70b7-46dd-939e-34553d73fda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's add a column with the values from the previous week (one lag)\n",
    "df[\"t-1\"] = df[\"co2\"].shift(1)\n",
    "df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5ad3ad-6294-496b-abb3-2fb2b8064624",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop to add columns with lags 1-4\n",
    "for i in range(1, 5):\n",
    "    df[f\"t-{i}\"] = df[\"co2\"].shift(i)\n",
    "df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3dac722-53cc-4205-aa6c-35e568c18099",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping early rows with NA values\n",
    "df_model = df.dropna()\n",
    "df_model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46af3be4-bfd9-4844-b823-4bb195c3ede0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our target is co2, the actual value for that rows' date\n",
    "y = df_model[\"co2\"]\n",
    "X = df_model.drop(columns=\"co2\")\n",
    "X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa964480-21e8-4f34-9e04-598ec434126c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating integer index for 75%/25% split\n",
    "idx_split = round(len(X) * 0.75)\n",
    "idx_split\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb3292e-30e3-4d96-9e34-cf2c51f9fc5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What date corresponds to 75%?\n",
    "split_date = X.index[idx_split]\n",
    "split_date\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d937b8b3-9652-4a8e-96cb-6e8ef387e5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time Series train-test-split\n",
    "# All data before split date is training\n",
    "X_train = X.loc[:split_date]\n",
    "y_train = y.loc[:split_date]\n",
    "# All data after split date is testing\n",
    "X_test = X.loc[split_date:]\n",
    "y_test = y.loc[split_date:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5722a7c1-440e-47b8-aba6-23d773cc367a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the training and test data\n",
    "ax = y_train.plot(label=\"Training Data\")\n",
    "y_test.plot(ax=ax, label=\"Test Data\")\n",
    "# Saving the date as a string for matplotlib\n",
    "split_date_str = split_date.strftime(\"%Y-%m-%d\")\n",
    "# Annotating the split data\n",
    "ax.axvline(\n",
    "    split_date_str, color=\"black\", ls=\"--\", lw=1.0, label=f\"Split Date:{split_date_str}\"\n",
    ")\n",
    "ax.set(ylabel=\"CO2 (PPM)\", xlabel=\"Week\", title=\"CO2 Levels Over Time\")\n",
    "ax.legend();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27be63f-f227-4072-9f7b-8b6e5767a61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a Linear Regression Model\n",
    "lin_reg = LinearRegression()\n",
    "# Fit on the training data\n",
    "lin_reg.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad596281-b5d9-44cd-8df8-6d567fca7810",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making a Series of our test predictions\n",
    "y_pred_test = lin_reg.predict(X_test)\n",
    "y_pred_test = pd.Series(y_pred_test, index=y_test.index)\n",
    "y_pred_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6da45c0-dd8d-49a1-a47c-a082d17cce09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the training and test data and predictions for test\n",
    "ax = y_train.plot(label=\"Training Data\")\n",
    "y_test.plot(ax=ax, label=\"Test Data\")\n",
    "y_pred_test.plot(ax=ax, label=\"Predicted\", color=\"green\")\n",
    "# Saving the date as a string for matplotlib\n",
    "split_date_str = split_date.strftime(\"%Y-%m-%d\")\n",
    "# Annotating the split data\n",
    "ax.axvline(\n",
    "    split_date_str, color=\"black\", ls=\"--\", lw=1.0, label=f\"Split Date:{split_date_str}\"\n",
    ")\n",
    "ax.set(ylabel=\"CO2 (PPM)\", xlabel=\"Week\", title=\"CO2 Levels Over Time\")\n",
    "ax.legend();\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286928b6-6c12-49f5-b7ae-dd196e1beaaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting predictions and metrics\n",
    "evaluate_regression(lin_reg, X_train, y_train, X_test, y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f28d0ae-7fe4-47d2-bb1d-83397b54d692",
   "metadata": {},
   "source": [
    "# Stationarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30dc6051-1d2d-41b1-889e-e89c0f1d19f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import  statsmodels.tsa.api as tsa # new import\n",
    "from sklearn import set_config\n",
    "#set_config(transform_output=\"pandas\")\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 4)\n",
    "sns.set_context(\"talk\", font_scale=0.9)\n",
    "# set random seed\n",
    "SEED = 321\n",
    "np.random.seed(SEED)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15dc98f-3632-4b47-bc03-b9e555ff0387",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating a simulated white noise time series (one value)\n",
    "c = 49\n",
    "noise_t = np.random.normal()\n",
    "# Add the random value to the mean to get the duration of the lap for one day\n",
    "y_t= c + noise_t\n",
    "y_t\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d60a977-45b1-4848-8001-0d1bbae43391",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating a simulated white noise time series for 120 days\n",
    "c = 49\n",
    "n_lags = 120\n",
    "y = []\n",
    "for t in range(n_lags):\n",
    "    \n",
    "    noise_t = np.random.normal(size=1)\n",
    "    y_t = c + noise_t[0] # slicing 0 to get value instead of arrays\n",
    "    y.append(y_t)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e7e9ce-2825-43d7-bfb2-ff411c55c4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convet list to a Pandas Series\n",
    "ts_white_noise = pd.Series(y, name='Simulated White Noise')     \n",
    "ts_white_noise\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf36469-0112-44c2-8605-41facf093aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the white noise series with annotated mean\n",
    "ax = ts_white_noise.plot()\n",
    "ax.set(title='Bus Route Duration\\n(Simulated White Noise Series',\n",
    "       ylabel='$Y_t', xlabel='observation/time');\n",
    "ax.axhline( ts_white_noise.mean(),  color='k', ls='--',\n",
    "           label=f'mean: {ts_white_noise.mean():.2f}');\n",
    "ax.legend();\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a2554b-9c0c-4a8c-a7bc-99c6e77b9ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running the adfuller test to demonstrate return\n",
    "tsa.adfuller(ts_white_noise)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b11da17-d9d1-41f0-8ad7-38e88c2ec0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving each output separately\n",
    "(test_stat, pval, nlags, nobs, crit_vals_d, icbest) = tsa.adfuller(ts_white_noise)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45892c5-fd37-4dc3-90ff-4e4fc3c9cf34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the most important results as a dictionary\n",
    "adfuller_results = {'Test Statistic': test_stat,\n",
    "                    \"# of Lags Used\":nlags, \n",
    "                   '# of Observations':nobs,\n",
    "                    'p-value': round(pval,6)}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d029a0ed-f9fc-46a9-bc8a-e0a727b887a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding interpretation of p-value to dictionary\n",
    "alpha =.05\n",
    "adfuller_results['sig/stationary?'] = pval < alpha\n",
    "adfuller_results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8846344-4faf-4ece-95c6-0f81a3c999a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert dictionary of results to a dataframe\n",
    "adfuller_df = pd.DataFrame(adfuller_results, index=['AD Fuller Test'])\n",
    "adfuller_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98af923-1282-4ec7-bd2f-2034c4c0228c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom function for Ad Fuller Test\n",
    "def get_adfuller_results(ts, alpha=.05, label='adfuller', **kwargs): #kwargs for adfuller()\n",
    "    # Saving each output\n",
    "    (test_stat, pval, nlags, nobs, crit_vals_d, \n",
    "    icbest ) = tsa.adfuller(ts, **kwargs)\n",
    "    # Converting output to a dictionary with the interpretation of p\n",
    "    adfuller_results = {'Test Statistic': test_stat,\n",
    "                        \"# of Lags Used\":nlags, \n",
    "                       '# of Observations':nobs,\n",
    "                        'p-value': round(pval,6),\n",
    "                        'alpha': alpha,\n",
    "                       'sig/stationary?': pval < alpha}\n",
    "    return pd.DataFrame(adfuller_results, index =[label])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a56080-b23f-4002-bff2-47a987e8ab48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the function\n",
    "adfuller_results = get_adfuller_results(ts_white_noise, label='White Noise')\n",
    "adfuller_results\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da50cb6e-9c40-4914-8add-173249cce91d",
   "metadata": {},
   "source": [
    "# \n",
    "Autocorrelation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8d89f3-412e-4414-844b-c748568ccc91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shift the data one step \n",
    "ts_lag1 = ts_white_noise.shift(1)\n",
    "ts_lag1 = ts_lag1.rename('Lag 1')\n",
    "ts_lag1.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f5aaad-6b9a-4661-9596-e291e945d05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine original ts + with lag 1\n",
    "ts_lagged = pd.concat([ts_white_noise,ts_lag1], axis=1)\n",
    "ts_lagged.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c1c6a4-17f3-4ca5-b058-ddff3e8032c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for correlation\n",
    "ts_lagged.corr()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e367c71e-7232-4c37-b369-2d2b6cc7e555",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate 20 time-shifted columns\n",
    "ts_lagged = pd.DataFrame()\n",
    "total_shifts = 20\n",
    "for t in range(0,total_shifts+1):    \n",
    "    ts_lagged[f\"Lag {t}\"] =  ts_white_noise.shift(t)\n",
    "ts_lagged.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717c2837-6fae-413f-b830-14cbb4c9b93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlations for all values\n",
    "corr = ts_lagged.corr()\n",
    "corr.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5f5391-ae8b-41c7-9bc5-ec06964a5f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slice out the original ts (lag 0)\n",
    "auto_corr = corr['Lag 0']\n",
    "auto_corr\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c137eff-8de3-4dd9-bd82-1faf6712317e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the calculated correlations\n",
    "ax = auto_corr.plot(style='o:')\n",
    "ax.axhline(0, color='k', ls='--', zorder=-1);\n",
    "ax.set(ylabel='Autocorrelation', xlabel='Time Lag');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6142ec1e-20c0-4101-9bea-ca3d1247efd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting autocorrelation with built in function\n",
    "fig = tsa.graphics.plot_acf(ts_white_noise);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef164b2-d767-444c-9b48-baaffc6baf12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating a simulated random walk \n",
    "first_t = 150\n",
    "y_walk = [first_t]\n",
    "n_lags=120\n",
    "for t in range(1,n_lags):\n",
    "    # get the previous time lag's value\n",
    "    y_prev_t = y_walk[t-1]\n",
    "    \n",
    "    # Get new noise\n",
    "    noise_t = np.random.normal(size=1)\n",
    "    \n",
    "    # Add noise on to previous value\n",
    "    y_t = y_prev_t + noise_t[0] # slicing 0 to get value instead of arrays\n",
    "    y_walk.append(y_t)\n",
    "    \n",
    "ts_rand_walk = pd.Series(y_walk, name='Simulated Random Walk')    \n",
    "ts_rand_walk\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c531cc-ce21-4d1e-9ad3-241420c18a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the random walk time series\n",
    "ax = ts_rand_walk.plot(label='Random Walk')\n",
    "ax.set(ylabel='$Y_t', title='Simulated Random Walk Time Series');\n",
    "ax.axhline(ts_rand_walk.mean(), color='black', ls=':', label='mean');\n",
    "ax.legend();\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bcf9b76-136c-4df7-9a0a-e675bbd93714",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test random walk forstationarity\n",
    "get_adfuller_results(ts_rand_walk)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ddce956-cb34-4e03-beed-e913a96f14b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for autocorrelation\n",
    "tsa.graphics.plot_acf(ts_rand_walk);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2dfb11-1a6b-4f1e-b8fd-0d3ef462d987",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Orignal random walk\n",
    "ts_rand_walk.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3551240-dd45-4fd3-9d29-71587faaadf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Differenced random walk\n",
    "ts_rand_walk.diff().head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47fc8795-42e6-4276-bfc8-12d5e8e0da77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the differenced random walk\n",
    "ts_rand_walk_diff = ts_rand_walk.diff().dropna()\n",
    "ts_rand_walk_diff.plot(title='Random Walk - Differenced');\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5fe54a-4da5-453b-8671-81582720266e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test differenced random walk for stationarity\n",
    "get_adfuller_results(ts_rand_walk_diff)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27dc196f-7b7f-4edb-a512-2a1a31b5d266",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check differenced random walk for autocorrelation\n",
    "tsa.graphics.plot_acf(ts_rand_walk_diff)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68609d19-1dfd-4fad-89e0-310b2eeea943",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating simulated random walk with a drift\n",
    "first_t = 150\n",
    "c = .3\n",
    "y_walk_drift = [first_t]\n",
    "for t in range(1,n_lags):\n",
    "    # get the previous time lag's value\n",
    "    y_prev_t = y_walk_drift[t-1]\n",
    "    \n",
    "    # Get new noise\n",
    "    noise_t = np.random.normal(size=1)\n",
    "    # Add noise on to previous value\n",
    "    y_t = c + y_prev_t + noise_t[0]# slicing 0 to get value instead of arrays\n",
    "    y_walk_drift.append(y_t)\n",
    "    \n",
    "ts_rand_walk_drift = pd.Series(y_walk_drift, name = \"Simulated Random walk (+dift)\")    \n",
    "ax = ts_rand_walk_drift.plot()\n",
    "ax.set(ylabel='$Y_t, title='Simulated Random Walk with a Drift Time Series');\n",
    "ax.axhline(ts_rand_walk_drift.mean(), color='black', ls=':');\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e827376f-64e9-40a2-9ea6-ee1601866959",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare random walk with a drift vs without\n",
    "ax = ts_rand_walk_drift.plot(label='Random Walk with a Drift')\n",
    "ts_rand_walk.plot(ax=ax, label='Random Walk (no drift)')\n",
    "ax.legend();\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b7cb09-845f-40fa-b449-c550cfd299f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test random walk with a drift for stationarity\n",
    "get_adfuller_results(ts_rand_walk_drift)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc791d5b-f039-4ab2-b9a2-0f9c36b71501",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test random walk a with a drift for autocorrelation\n",
    "tsa.graphics.plot_acf(ts_rand_walk_drift);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a133923-3d0a-410e-a10e-d8e56a6c13b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Difference the random walk with a drift\n",
    "ts_rand_walk_drift_diff = ts_rand_walk_drift.diff().dropna()\n",
    "# Visualize the differenced random walk with a drift\n",
    "ts_rand_walk_drift_diff.plot(title='Random Walk - Differenced');\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad53ee61-369a-472b-aa5d-c023d4775970",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm that a differenced random walk with drift is stationary\n",
    "get_adfuller_results(ts_rand_walk_drift_diff)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19da654f-48e6-4294-90b7-58953028e5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the differenced random walk with drift for autocorrelation\n",
    "tsa.graphics.plot_acf(ts_rand_walk_drift_diff)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166f79f8-b901-4b30-886b-ae5c51d68602",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6aff7b53-4476-400b-9a44-d037bc248f37",
   "metadata": {},
   "source": [
    "# Autoregressive (AR) Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c66039-fa71-45a9-a1ee-0efc5b1b8231",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.tsa.api as tsa\n",
    "from pmdarima.model_selection import train_test_split\n",
    "from pmdarima.arima.utils import ndiffs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b93798a-c0a6-473f-b682-8298501651c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom function for Ad Fuller Test\n",
    "def get_adfuller_results(ts, alpha=.05, label='adfuller', **kwargs): #kwargs for adfuller()\n",
    "    # Saving each output\n",
    "    (test_stat, pval, nlags, nobs, crit_vals_d, \n",
    "    icbest ) = tsa.adfuller(ts, **kwargs)\n",
    "    # Converting output to a dictionary with the interpretation of p\n",
    "    adfuller_results = {'Test Statistic': test_stat,\n",
    "                        \"# of Lags Used\":nlags, \n",
    "                       '# of Observations':nobs,\n",
    "                        'p-value': round(pval,6),\n",
    "                        'alpha': alpha,\n",
    "                       'sig/stationary?': pval < alpha}\n",
    "    return pd.DataFrame(adfuller_results, index =[label])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c4d5d7-ed0b-4a33-b168-4c5179d85308",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in data\n",
    "ts = pd.read_csv('AR_lesson_ts.csv', index_col = 'date')\n",
    "ts.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b255b65e-46f0-4847-936f-65213b6c298c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make index datetime\n",
    "ts.index = pd.to_datetime(ts.index)\n",
    "# We have weekly data so we will set our frequency to W\n",
    "ts.index.freq= \"W\"\n",
    "# Make a series\n",
    "ts = ts['dollars']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16049609-cd37-455f-8917-c453591a7ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for nulls\n",
    "ts.isna().sum().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de002bae-f608-45b8-97cb-d6412137c92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the time series\n",
    "ts.plot();\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05c2379-026b-4eb0-afcf-4cf99c260677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make acf plot of raw data to look for seasonality\n",
    "tsa.graphics.plot_acf(ts);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90de3e4-4ecd-4e59-b7c3-58e5a856e1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call custom function to check to see if data is stationary\n",
    "get_adfuller_results(ts)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf21809-9b3d-4a37-b127-126064124834",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pmdarima.arima.utils import ndiffs\n",
    "# use ndiffs to determine differencing\n",
    "d = ndiffs(ts)\n",
    "print(f'd is {d}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bfb7db8-c76c-4681-847e-7f3dd75a14bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make acf plot to determine if this is AR or MA \n",
    "tsa.graphics.plot_acf(ts);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2c93c4-5b80-492c-8ad8-b90d59f3d003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine the PACF plot to determine order of AR model\n",
    "tsa.graphics.plot_pacf(ts);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b130a59-e5aa-4da6-a824-2b22a77a0960",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pmdarima.model_selection import train_test_split\n",
    "# tts\n",
    "train, test = train_test_split(ts, test_size=.20)\n",
    "# Visualize the train and test data\n",
    "ax = train.plot(label='Train')\n",
    "test.plot(ax=ax, label='Test')\n",
    "ax.legend();\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242ba4e2-24d0-4a02-a865-39cb4ea843b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# proper way to import tsa submodule\n",
    "import statsmodels.tsa.api as tsa\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e944d9-a80b-4320-95be-d5d9437b3602",
   "metadata": {},
   "source": [
    "We will discuss ARIMA models in depth in an upcoming lesson, but for now, the main thing to know is that an ARIMA model's order is defined by 3 parameters (p,d,q):\r\n",
    "- \r\n",
    "AR(p): an auto-regressive component, building coefficients for previous lagged value- s\r\n",
    "Integration(d): applying differencing to achieve stationari- ty\r\n",
    "MA(q): a moving average component, building coefficients based on the models' errors at previous time lags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f9f1d5-76be-4893-a218-73f76b74e90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First define the orders (p,d,q)\n",
    "p = 1 # AR(1) model based on significant lags in PACF\n",
    "d = 0 # No differcing needed to make stationary\n",
    "q = 0 # q will be used for MA models (set to 0 for an AR only model)\n",
    "# Now instantiate the model with the data and fit\n",
    "ar_1_model = tsa.ARIMA(train, order = (p,d,q)).fit()\n",
    "ar_1_model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a442266-4add-44b3-b7ba-0f346233e9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain the parameters of the fit model\n",
    "ar_1_model.params\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3175f2fb-61b1-49ad-965a-4a9f6d296de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain forecast as a dataframe with confidence intervals\n",
    "forecast_df = ar_1_model.get_forecast(steps=len(test)).summary_frame()\n",
    "forecast_df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3b1f5b-65f7-412f-b591-cc16643108b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_forecast(ts_train, ts_test, forecast_df, n_train_lags=None, \n",
    "                  figsize=(10,4), title='Comparing Forecast vs. True Data'):\n",
    "    ### PLot training data, and forecast (with upper/,lower ci)\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    # setting the number of train lags to plot if not specified\n",
    "    if n_train_lags==None:\n",
    "        n_train_lags = len(ts_train)\n",
    "            \n",
    "    # Plotting Training  and test data\n",
    "    ts_train.iloc[-n_train_lags:].plot(ax=ax, label=\"train\")\n",
    "    ts_test.plot(label=\"test\", ax=ax)\n",
    "    # Plot forecast\n",
    "    forecast_df['mean'].plot(ax=ax, color='green', label=\"forecast\")\n",
    "    # Add the shaded confidence interval\n",
    "    ax.fill_between(forecast_df.index, \n",
    "                    forecast_df['mean_ci_lower'],\n",
    "                   forecast_df['mean_ci_upper'],\n",
    "                   color='green', alpha=0.3,  lw=2)\n",
    "    # set the title and add legend\n",
    "    ax.set_title(title)\n",
    "    ax.legend();\n",
    "    \n",
    "    return fig, ax\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63c07f1-f16f-4c42-9509-83c94849e060",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the custom function to plot the forecasts with confidence intervals and true values\n",
    "plot_forecast(train, test, forecast_df);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6664ddf9-0bb9-4437-9d4a-c0b0cb5c97d8",
   "metadata": {},
   "source": [
    "Add MAPE(Mean Absolute Percentage Error) to function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9caca8c-0f3e-4a05-8e33-de594af20ad9",
   "metadata": {},
   "source": [
    "# MA Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be9a712-ed96-4834-be49-5b3c06d4c5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, mean_absolute_percentage_error\n",
    "\n",
    "def regression_metrics_ts(ts_true, ts_pred, label=\"\", verbose=True, output_dict=False,):\n",
    "    # Get metrics\n",
    "    mae = mean_absolute_error(ts_true, ts_pred)\n",
    "    mse = mean_squared_error(ts_true, ts_pred)\n",
    "    rmse = mean_squared_error(ts_true, ts_pred, squared=False)\n",
    "    r_squared = r2_score(ts_true, ts_pred)\n",
    "    mae_perc = mean_absolute_percentage_error(ts_true, ts_pred) * 100\n",
    "\n",
    "    if verbose == True:\n",
    "        # Print Result with label\n",
    "        header = \"---\" * 20\n",
    "        print(header, f\"Regression Metrics: {label}\", header, sep=\"\\n\")\n",
    "        print(f\"- MAE = {mae:,.3f}\")\n",
    "        print(f\"- MSE = {mse:,.3f}\")\n",
    "        print(f\"- RMSE = {rmse:,.3f}\")\n",
    "        print(f\"- R^2 = {r_squared:,.3f}\")\n",
    "        print(f\"- MAPE = {mae_perc:,.2f}%\")\n",
    "\n",
    "    if output_dict == True:\n",
    "        metrics = {\n",
    "            \"Label\": label,\n",
    "            \"MAE\": mae,\n",
    "            \"MSE\": mse,\n",
    "            \"RMSE\": rmse,\n",
    "            \"R^2\": r_squared,\n",
    "            \"MAPE(%)\": mae_perc,\n",
    "        }\n",
    "        return metrics\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc294f5-7ac0-467a-be93-ef0ac6bd634f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain metrics\n",
    "regression_metrics_ts(test, forecast_df['mean'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da57ca7-19f9-4309-94ef-1d75b6cc4a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom function for Ad Fuller Test\n",
    "def get_adfuller_results(ts, alpha=.05, label='adfuller', **kwargs): #kwargs for adfuller()\n",
    "    # Saving each output\n",
    "    (test_stat, pval, nlags, nobs, crit_vals_d, \n",
    "    icbest ) = tsa.adfuller(ts, **kwargs)\n",
    "    # Converting output to a dictionary with the interpretation of p\n",
    "    adfuller_results = {'Test Statistic': test_stat,\n",
    "                        \"# of Lags Used\":nlags, \n",
    "                       '# of Observations':nobs,\n",
    "                        'p-value': round(pval,6),\n",
    "                        'alpha': alpha,\n",
    "                       'sig/stationary?': pval < alpha}\n",
    "    return pd.DataFrame(adfuller_results, index =[label])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cfc3151-5480-452c-bf21-e1ec11ab8a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in data\n",
    "ts = pd.read_csv('MA_lesson_ts.csv', index_col = 'date')\n",
    "ts.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7429d52-f03a-4b2a-8ffa-6fb729de0d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have monthly data so we will set our frequency to M\n",
    "ts.index.freq= \"M\"\n",
    "# Define the series\n",
    "ts = ts['value']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cdb782e-3fbc-4048-aae6-9ec274695152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for nulls\n",
    "ts.isna().sum()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a9e9a3-b8c2-426f-b9de-4c1c3a65af2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the time series\n",
    "ts.plot();\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879e6f93-9a2a-44e2-bc4d-d82c1d2fc139",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make acf plot of raw data to look for seasonality\n",
    "tsa.graphics.plot_acf(ts);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e29241d-5d2d-423f-abbd-6ff105d7e609",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call custom function to check to see if data is stationary\n",
    "get_adfuller_results(ts)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca30a1a7-c7e9-4169-9fea-1a0fd7163202",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check differencing with ndiffs\n",
    "d = ndiffs(ts)\n",
    "print (f'd = {d}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd5cc02-bbf3-4aaa-8262-e5abbb6e6e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### NEW FUNCTION FOR COMBINED ACF/PACF WITH ANNOTATIONS\n",
    "def plot_acf_pacf(ts, nlags=40, figsize=(10, 5), \n",
    "                  annotate_sig=False, alpha=.05,\n",
    "                 acf_kws={}, pacf_kws={},  \n",
    "                  annotate_seas=False, m = None,\n",
    "                 seas_color='black'):\n",
    "    \n",
    "    fig, axes = plt.subplots(nrows=2, figsize=figsize)\n",
    "    \n",
    "    # Sig lags line style\n",
    "    sig_vline_kwargs = dict( ls=':', lw=1, zorder=0, color='red')\n",
    "    # ACF\n",
    "    tsa.graphics.plot_acf(ts, ax=axes[0], lags=nlags, **acf_kws)\n",
    "    \n",
    "    ## Annotating sig acf lags\n",
    "    if annotate_sig == True:\n",
    "        sig_acf_lags = get_sig_lags(ts,nlags=nlags,alpha=alpha, type='ACF')\n",
    "        for lag in sig_acf_lags:\n",
    "            axes[0].axvline(lag,label='sig', **sig_vline_kwargs )\n",
    "    # PACF\n",
    "    tsa.graphics.plot_pacf(ts,ax=axes[1], lags=nlags, **pacf_kws)\n",
    "    \n",
    "    ## Annotating sig pacf lags\n",
    "    if annotate_sig == True:\n",
    "        ## ANNOTATING SIG LAGS\n",
    "        sig_pacf_lags = get_sig_lags(ts,nlags=nlags,alpha=alpha, type='PACF')\n",
    "        for lag in sig_pacf_lags:\n",
    "            axes[1].axvline(lag, label='sig', **sig_vline_kwargs)\n",
    "    \n",
    "    ### ANNOTATE SEASONS\n",
    "    if annotate_seas == True:\n",
    "        # Ensure m was defined\n",
    "        if m is None:\n",
    "            raise Exception(\"Must define value of m if annotate_seas=True.\")\n",
    "        ## Calculate number of complete seasons to annotate\n",
    "        n_seasons = nlags//m \n",
    "        # Seasonal Lines style\n",
    "        seas_vline_kwargs = dict( ls='--',lw=1, alpha=.7, color=seas_color, zorder=-1)\n",
    "        \n",
    "        ## for each season, add a line\n",
    "        for i in range(1, n_seasons+1):\n",
    "            axes[0].axvline(m*i, **seas_vline_kwargs, label=\"season\")\n",
    "            axes[1].axvline(m*i, **seas_vline_kwargs, label=\"season\")\n",
    "    fig.tight_layout()\n",
    "    \n",
    "    return fig\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb1cf76-e3da-4ac3-9cb1-936a4fd2527d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's call our custom acf/pacf plot on our stationary (d = 0) data\n",
    "plot_acf_pacf(ts);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c30660c-39d9-4883-962a-2fdb592cd0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tts\n",
    "train, test = train_test_split(ts, test_size=.20)\n",
    "# Visualize the train and test data\n",
    "ax = train.plot(label='Train')\n",
    "test.plot(ax=ax, label='Test')\n",
    "ax.legend();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58b8147-c8d4-4687-a6f2-9e08e405f054",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First define the orders (p,d,q)\n",
    "p = 0 # p is us ed for AR models (set to 0 for an MA only model)\n",
    "d = 0 # no differcing was required to make the data stationary\n",
    "q = 2 # q based on significant lags in ACF\n",
    "# Now instantiate the model with the data and fit\n",
    "ma_2_model = tsa.ARIMA(train, order = (p,d,q)).fit()\n",
    "ma_2_model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7837a60d-0d7a-4385-a431-023f0426d70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain the parameters of the fit model\n",
    "ma_2_model.params\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09bf1e25-dfc7-4966-9f41-e44be1c3f35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain forecast as a dataframe with confidence intervals\n",
    "forecast_df = ma_2_model.get_forecast(steps=len(test)).summary_frame()\n",
    "# Call the custom function to plot the forecasts with confidence intervals and true values\n",
    "plot_forecast(train, test, forecast_df);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d684c6-416d-47c9-b645-12a45534aced",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in data\n",
    "ts = pd.read_csv('AR_MA_lesson_ts.csv', parse_dates = ['date'], index_col = 'date')\n",
    "ts.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65544769-8613-40f2-be66-e29e18cabfab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have daily data so we will set our frequency to D\n",
    "ts.index.freq= \"D\"\n",
    "ts.index\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b643db5c-c889-434e-b425-8de41a8c94c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for nulls\n",
    "ts.isna().sum().sum()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4ff1e7-932d-4a48-b6c5-7ba5cde669d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the time series\n",
    "ts.plot();\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15bf9d2-3902-4d31-90c0-c241595a59be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call custom function to check to see if data is stationary\n",
    "get_adfuller_results(ts)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c6ea12-bb38-43a6-b8af-3915209da8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check to see how many differencing are needed\n",
    "ndiffs(ts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09b63cf-a645-4462-bbc0-410d63d83bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to apply differencing one time\n",
    "ts_diff = ts.diff().dropna()\n",
    "# Confirm stationarity with adfuller test\n",
    "get_adfuller_results(ts_diff)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a48b22-98ee-41fd-a6f1-88a6fd8c04aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's call our custom acf/pacf plot on our stationary (d = 1) data\n",
    "plot_acf_pacf(ts_diff);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c363466e-47da-4c35-bcc0-6b3345bbaa3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First define the orders (p,d,q)\n",
    "p = 1 # p is used for AR component of AR-MA model\n",
    "d = 1 # 1 differcing needed to make stationary\n",
    "q = 1 # q is used for MA component of AR-MA model\n",
    "# Now instantiate the model with the data and fit\n",
    "ar_ma_model = tsa.ARIMA(train, order = (p,d,q)).fit()\n",
    "ar_ma_model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591cad84-0137-418c-9230-d0f249bbfe30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain the parameters of the fit model\n",
    "ar_ma_model.params\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf418afe-b20e-4c51-8d7a-acbee67cb001",
   "metadata": {},
   "source": [
    "# Comparing Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7a1a26-e69f-4e93-b07b-7318b4426274",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain summary of model\n",
    "ma_2_model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f647d5d-6406-48f6-8bb4-2f6e6b4ba98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain diagnostic plots\n",
    "fig = ma_2_model.plot_diagnostics()\n",
    "fig.set_size_inches(10,6)\n",
    "fig.tight_layout()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a36b75b-441f-4b34-8370-7f45e8d7f79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First define the orders (p,d,q)\n",
    "p = 0 \n",
    "d = 0 \n",
    "q = 1 \n",
    "\n",
    "# Now instantiate the model with the data and fit\n",
    "ma_1_model = tsa.ARIMA(train, order = (p,d,q)).fit()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d31818-a0d7-4125-9217-3b4e13c8893e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain model summary\n",
    "ma_1_model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eac45a7-9e55-4295-9d8a-64bf91e0b854",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain diagnostic plots\n",
    "fig = ma_1_model.plot_diagnostics()\n",
    "fig.set_size_inches(10,6)\n",
    "fig.tight_layout()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37e8174-6499-4b8d-beeb-fa3adbd2f283",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First define the orders (p,d,q)\n",
    "p = 1 \n",
    "d = 0 \n",
    "q = 2  \n",
    "\n",
    "# Now instantiate the model with the data and fit\n",
    "ar_1_ma_2_model = tsa.ARIMA(train, order = (p,d,q)).fit()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55f0abc-6658-4db9-8a60-f238f56831d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain diagnostic plots\n",
    "fig = ar_1_ma_2_model.plot_diagnostics()\n",
    "fig.set_size_inches(10,6)\n",
    "fig.tight_layout()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0af9832-5d71-49ad-b3d5-8b75f484ba13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at AIC of all three models\n",
    "print(f'MA(2) had an AIC of {ma_2_model.aic.round(2)}')\n",
    "print(f'MA(1) had an AIC of {ma_1_model.aic.round(2)}')\n",
    "print(f'AR(1)MA(2) had an AIC of {ar_1_ma_2_model.aic.round(2)}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35fc06b8-0b6f-46fb-b288-5d6b74001bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "â€‹# Looking at BIC of all three models\n",
    "print(f'MA(2) had a BIC of {ma_2_model.bic.round(2)}')\n",
    "print(f'MA(1) had a BIC of {ma_1_model.bic.round(2)}')\n",
    "print(f'AR(1)MA(2) had a BIC of {ar_1_ma_2_model.bic.round(2)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e7f5ee3-8a88-492c-9382-a3ad1b575f93",
   "metadata": {},
   "source": [
    "# ARIMA Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca06a2b2-2e69-4572-8849-66d341259b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "â€‹import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import statsmodels.tsa.api as tsa\n",
    "from pmdarima.model_selection import train_test_split\n",
    "from pmdarima.arima.utils import ndiffs\n",
    "\n",
    "# Set wide fig size for plots\n",
    "plt.rcParams['figure.figsize']=(12,3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf80bc5-9c38-42af-9ed4-0a9d790e758e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_forecast(ts_train, ts_test, forecast_df, n_train_lags=None, \n",
    "                  figsize=(10,4), title='Comparing Forecast vs. True Data'):\n",
    "    ### PLot training data, and forecast (with upper/,lower ci)\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "\n",
    "    # setting the number of train lags to plot if not specified\n",
    "    if n_train_lags==None:\n",
    "        n_train_lags = len(ts_train)\n",
    "            \n",
    "    # Plotting Training  and test data\n",
    "    ts_train.iloc[-n_train_lags:].plot(ax=ax, label=\"train\")\n",
    "    ts_test.plot(label=\"test\", ax=ax)\n",
    "\n",
    "    # Plot forecast\n",
    "    forecast_df['mean'].plot(ax=ax, color='green', label=\"forecast\")\n",
    "\n",
    "    # Add the shaded confidence interval\n",
    "    ax.fill_between(forecast_df.index, \n",
    "                    forecast_df['mean_ci_lower'],\n",
    "                   forecast_df['mean_ci_upper'],\n",
    "                   color='green', alpha=0.3,  lw=2)\n",
    "\n",
    "    # set the title and add legend\n",
    "    ax.set_title(title)\n",
    "    ax.legend();\n",
    "    \n",
    "    return fig, ax\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8dad7df-2057-4836-8f3b-b2f6d63bcd89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom function for Ad Fuller Test\n",
    "def get_adfuller_results(ts, alpha=.05, label='adfuller', **kwargs): #kwargs for adfuller()\n",
    "    # Saving each output\n",
    "    (test_stat, pval, nlags, nobs, crit_vals_d, \n",
    "    icbest ) = tsa.adfuller(ts, **kwargs)\n",
    "    # Converting output to a dictionary with the interpretation of p\n",
    "    adfuller_results = {'Test Statistic': test_stat,\n",
    "                        \"# of Lags Used\":nlags, \n",
    "                       '# of Observations':nobs,\n",
    "                        'p-value': round(pval,6),\n",
    "                        'alpha': alpha,\n",
    "                       'sig/stationary?': pval < alpha}\n",
    "    return pd.DataFrame(adfuller_results, index =[label])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc28e15-15db-4e8a-884b-d08c08b94c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, mean_absolute_percentage_error\n",
    "\n",
    "def regression_metrics_ts(ts_true, ts_pred, label=\"\", verbose=True, output_dict=False,):\n",
    "    # Get metrics\n",
    "    mae = mean_absolute_error(ts_true, ts_pred)\n",
    "    mse = mean_squared_error(ts_true, ts_pred)\n",
    "    rmse = mean_squared_error(ts_true, ts_pred, squared=False)\n",
    "    r_squared = r2_score(ts_true, ts_pred)\n",
    "    mae_perc = mean_absolute_percentage_error(ts_true, ts_pred) * 100\n",
    "\n",
    "    if verbose == True:\n",
    "        # Print Result with label\n",
    "        header = \"---\" * 20\n",
    "        print(header, f\"Regression Metrics: {label}\", header, sep=\"\\n\")\n",
    "        print(f\"- MAE = {mae:,.3f}\")\n",
    "        print(f\"- MSE = {mse:,.3f}\")\n",
    "        print(f\"- RMSE = {rmse:,.3f}\")\n",
    "        print(f\"- R^2 = {r_squared:,.3f}\")\n",
    "        print(f\"- MAPE = {mae_perc:,.2f}%\")\n",
    "\n",
    "    if output_dict == True:\n",
    "        metrics = {\n",
    "            \"Label\": label,\n",
    "            \"MAE\": mae,\n",
    "            \"MSE\": mse,\n",
    "            \"RMSE\": rmse,\n",
    "            \"R^2\": r_squared,\n",
    "            \"MAPE(%)\": mae_perc,\n",
    "        }\n",
    "        return metrics\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3cf88a-9205-46c1-980c-a96a155cede5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_acf_pacf(ts, nlags=40, figsize=(10, 5), \n",
    "                  annotate_sig=False, alpha=.05,\n",
    "                 acf_kws={}, pacf_kws={},  \n",
    "                  annotate_seas=False, m = None,\n",
    "                 seas_color='black'):\n",
    "    \n",
    "    fig, axes = plt.subplots(nrows=2, figsize=figsize)\n",
    "\n",
    "    \n",
    "    # Sig lags line style\n",
    "    sig_vline_kwargs = dict( ls=':', lw=1, zorder=0, color='red')\n",
    "\n",
    "    # ACF\n",
    "    tsa.graphics.plot_acf(ts, ax=axes[0], lags=nlags, **acf_kws)\n",
    "    \n",
    "    ## Annotating sig acf lags\n",
    "    if annotate_sig == True:\n",
    "        sig_acf_lags = get_sig_lags(ts,nlags=nlags,alpha=alpha, type='ACF')\n",
    "        for lag in sig_acf_lags:\n",
    "            axes[0].axvline(lag,label='sig', **sig_vline_kwargs )\n",
    "\n",
    "    # PACF\n",
    "    tsa.graphics.plot_pacf(ts,ax=axes[1], lags=nlags, **pacf_kws)\n",
    "    \n",
    "    ## Annotating sig pacf lags\n",
    "    if annotate_sig == True:\n",
    "        ## ANNOTATING SIG LAGS\n",
    "        sig_pacf_lags = get_sig_lags(ts,nlags=nlags,alpha=alpha, type='PACF')\n",
    "        for lag in sig_pacf_lags:\n",
    "            axes[1].axvline(lag, label='sig', **sig_vline_kwargs)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    ### ANNOTATE SEASONS\n",
    "    if annotate_seas == True:\n",
    "        # Ensure m was defined\n",
    "        if m is None:\n",
    "            raise Exception(\"Must define value of m if annotate_seas=True.\")\n",
    "\n",
    "        ## Calculate number of complete seasons to annotate\n",
    "        n_seasons = nlags//m \n",
    "\n",
    "        # Seasonal Lines style\n",
    "        seas_vline_kwargs = dict( ls='--',lw=1, alpha=.7, color=seas_color, zorder=-1)\n",
    "        \n",
    "        ## for each season, add a line\n",
    "        for i in range(1, n_seasons+1):\n",
    "            axes[0].axvline(m*i, **seas_vline_kwargs, label=\"season\")\n",
    "            axes[1].axvline(m*i, **seas_vline_kwargs, label=\"season\")\n",
    "\n",
    "    fig.tight_layout()\n",
    "    \n",
    "    return fig\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2703036a-05a9-4201-aa26-6dddca7aceab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in stock data\n",
    "ts = pd.read_csv(\"Data/msft-daily-closing-price.csv\", \n",
    "                  parse_dates=['Date'], index_col='Date')\n",
    "ts.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca6767c-a24b-4a7e-88cf-5d32598fc3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for 2015-2019 and only the adj close value\n",
    "ts = ts.loc['2015':'2019', 'Adj Close']\n",
    "ts.plot();â€‹\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8688ae-8ec7-40e8-bcf0-32cb8a21e857",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview the index\n",
    "ts.index\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb9254b-a461-4c71-a6a2-cbafa6afc486",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample for business day with 'B'\n",
    "ts = ts.resample('B').asfreq()\n",
    "ts\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55d056e-9fc0-40f5-8244-cf156fd71d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for nulls\n",
    "ts.isna().sum()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818bee4e-5dd8-481c-accb-3c8ad77f0c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect null values\n",
    "null = ts.isna()\n",
    "ts[null].head(20)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb1bad3-b0cc-4525-9fa0-c89974d6f233",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values with previous value\n",
    "ts = ts.fillna(method='ffill')\n",
    "ts.plot();\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0bca3d3-fe76-449e-abba-35f6077f1852",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the raw data for stationarity\n",
    "get_adfuller_results(ts)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15fb8cca-9dc7-4b4e-acb5-734498d2f3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Differencing the data once\n",
    "ts_diff = ts.diff().dropna()\n",
    "ts_diff.plot()\n",
    "# Checking for stationarity\n",
    "get_adfuller_results(ts_diff)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41703c7-de45-4a05-841c-50e90b818a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use ndiffs to determine differencing\n",
    "d = ndiffs(ts)\n",
    "print(f'd is {d}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c1f403-2df2-4545-8adb-1f4e12d5656c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Difference twice (d = 2)\n",
    "ts_diff2 =ts.diff().diff().dropna()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1556d58f-f70f-40c9-9aaf-46b57bea6887",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_acf_pacf(ts_diff2);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168ee518-665f-4435-87f9-0eeb03ecd950",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating number of test lags\n",
    "n_test_lags = 5*26\n",
    "\n",
    "# Modeling to predict 6 months into the future\n",
    "train, test = train_test_split(ts, test_size=n_test_lags)\n",
    "ax = train.plot(label='Train')\n",
    "test.plot(ax=ax, label='Test')\n",
    "ax.legend();\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70e8c35-fa8a-4baf-84bc-aa684094c2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model \n",
    "p = 0  # AR component \n",
    "\n",
    "d = 2  # Number of differencing required to make stationary\n",
    "\n",
    "q =  1 # MA component \n",
    "\n",
    "# Define and fit the model\n",
    "arima_model = tsa.ARIMA(train, order=(p,d,q)).fit()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855fde31-d577-4e73-936e-5deb3763ae8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain summary of forecast as dataframe\n",
    "forecast_df = arima_model.get_forecast(len(test)).summary_frame()\n",
    "\n",
    "# Plot the forecast with true values\n",
    "plot_forecast(train, test, forecast_df)\n",
    "\n",
    "# Obtain metrics\n",
    "regression_metrics_ts(test, forecast_df['mean'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f8c4e1-cae4-4b4a-becf-de0c93ea7a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain summary of model\n",
    "arima_model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b9ec13-8c77-4055-8851-39cb414cf3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain diagnostic plots\n",
    "fig = arima_model.plot_diagnostics()\n",
    "fig.set_size_inches(10,6)\n",
    "fig.tight_layout()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac31c383-b138-4315-8e90-9406fc3b7bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "# Define the value or range of values for p, d, q\n",
    "p_values = range(0, 4)  \n",
    "d_values = [2]          \n",
    "q_values = range(0, 4)  \n",
    "\n",
    "# Create combinations of pdq to test\n",
    "pdq_to_try = list(itertools.product(p_values, d_values, q_values))\n",
    "                                            \n",
    "pdq_to_try\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d699930-0722-4619-8edc-ee793f01cb01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define starting aic as infinity\n",
    "best_aic = float(\"inf\")  \n",
    "\n",
    "# define baseline for pdq\n",
    "best_pdq = (0,0,0)\n",
    "\n",
    "# Loop through each combination\n",
    "for pdq in pdq_to_try:\n",
    "    \n",
    "    model = tsa.ARIMA(train, order=pdq)\n",
    "                              \n",
    "    result = model.fit()\n",
    "    \n",
    "    print(pdq, result.aic)      \n",
    "    \n",
    "    # If lower, replace best AIC with new value\n",
    "    if result.aic < best_aic:\n",
    "        \n",
    "        best_aic = result.aic\n",
    "        best_pdq = pdq\n",
    "\n",
    "# Print the best orders and AIC score\n",
    "print(\"Best AIC:\", best_aic)\n",
    "print(\"Best pdq:\", best_pdq)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54174960-6d2e-48ca-9509-6b85de09de57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model with the best AIC\n",
    "p = 2  # AR component \n",
    "\n",
    "d = 2  # Number of differencing required to make stationary\n",
    "\n",
    "q =  3 # MA component \n",
    "\n",
    "# Define and fit the model\n",
    "ar_2_ma_3_model = tsa.ARIMA(train, order=(p,d,q)).fit()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5393f4bc-f03b-4c80-9332-64009a7a57d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain diagnostic plots\n",
    "fig = ar_2_ma_3_model.plot_diagnostics()\n",
    "fig.set_size_inches(10,6)\n",
    "fig.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a639a5a1-4d30-4894-be70-f20479168602",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain summary of forecast as dataframe\n",
    "forecast_df = ar_2_ma_3_model.get_forecast(len(test)).summary_frame()\n",
    "# Plot the forecast with true values\n",
    "plot_forecast(train, test, forecast_df)\n",
    "# Obtain metrics\n",
    "regression_metrics_ts(test, forecast_df['mean'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00cf0cba-8635-4289-8cc3-2fe7fc196730",
   "metadata": {},
   "source": [
    "# Seasonality in Modeling (SARIMA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d28ded6-12e1-4fd1-9250-01c67128b1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import statsmodels.tsa.api as tsa\n",
    "from pmdarima.model_selection import train_test_split\n",
    "from pmdarima.arima.utils import ndiffs, nsdiffs\n",
    "# set random seed\n",
    "SEED = 321\n",
    "np.random.seed(SEED)\n",
    "\n",
    "sns.set_context('notebook', font_scale=1.2)\n",
    "plt.rcParams['figure.figsize']=(12,3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab863707-fe33-4357-a8ea-542c94b5f5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_forecast(ts_train, ts_test, forecast_df, n_train_lags=None, \n",
    "                  figsize=(10,4), title='Comparing Forecast vs. True Data'):\n",
    "    ### PLot training data, and forecast (with upper/,lower ci)\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "\n",
    "    # setting the number of train lags to plot if not specified\n",
    "    if n_train_lags==None:\n",
    "        n_train_lags = len(ts_train)\n",
    "            \n",
    "    # Plotting Training  and test data\n",
    "    ts_train.iloc[-n_train_lags:].plot(ax=ax, label=\"train\")\n",
    "    ts_test.plot(label=\"test\", ax=ax)\n",
    "\n",
    "    # Plot forecast\n",
    "    forecast_df['mean'].plot(ax=ax, color='green', label=\"forecast\")\n",
    "\n",
    "    # Add the shaded confidence interval\n",
    "    ax.fill_between(forecast_df.index, \n",
    "                    forecast_df['mean_ci_lower'],\n",
    "                   forecast_df['mean_ci_upper'],\n",
    "                   color='green', alpha=0.3,  lw=2)\n",
    "\n",
    "    # set the title and add legend\n",
    "    ax.set_title(title)\n",
    "    ax.legend();\n",
    "    \n",
    "    return fig, ax\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81c73aa-6e7a-4673-8d89-2148856d0f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, mean_absolute_percentage_error\n",
    "\n",
    "def regression_metrics_ts(ts_true, ts_pred, label=\"\", verbose=True, output_dict=False,):\n",
    "    # Get metrics\n",
    "    mae = mean_absolute_error(ts_true, ts_pred)\n",
    "    mse = mean_squared_error(ts_true, ts_pred)\n",
    "    rmse = mean_squared_error(ts_true, ts_pred, squared=False)\n",
    "    r_squared = r2_score(ts_true, ts_pred)\n",
    "    mae_perc = mean_absolute_percentage_error(ts_true, ts_pred) * 100\n",
    "\n",
    "    if verbose == True:\n",
    "        # Print Result with label\n",
    "        header = \"---\" * 20\n",
    "        print(header, f\"Regression Metrics: {label}\", header, sep=\"\\n\")\n",
    "        print(f\"- MAE = {mae:,.3f}\")\n",
    "        print(f\"- MSE = {mse:,.3f}\")\n",
    "        print(f\"- RMSE = {rmse:,.3f}\")\n",
    "        print(f\"- R^2 = {r_squared:,.3f}\")\n",
    "        print(f\"- MAPE = {mae_perc:,.2f}%\")\n",
    "\n",
    "    if output_dict == True:\n",
    "        metrics = {\n",
    "            \"Label\": label,\n",
    "            \"MAE\": mae,\n",
    "            \"MSE\": mse,\n",
    "            \"RMSE\": rmse,\n",
    "            \"R^2\": r_squared,\n",
    "            \"MAPE(%)\": mae_perc,\n",
    "        }\n",
    "        return metrics\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd88a84-c1c0-496f-afdd-6e67bb05539b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom function for Ad Fuller Test\n",
    "def get_adfuller_results(ts, alpha=.05, label='adfuller', **kwargs): #kwargs for adfuller()\n",
    "    # Saving each output\n",
    "    (test_stat, pval, nlags, nobs, crit_vals_d, \n",
    "    icbest ) = tsa.adfuller(ts, **kwargs)\n",
    "    # Converting output to a dictionary with the interpretation of p\n",
    "    adfuller_results = {'Test Statistic': test_stat,\n",
    "                        \"# of Lags Used\":nlags, \n",
    "                       '# of Observations':nobs,\n",
    "                        'p-value': round(pval,6),\n",
    "                        'alpha': alpha,\n",
    "                       'sig/stationary?': pval < alpha}\n",
    "    return pd.DataFrame(adfuller_results, index =[label])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f323146-a4a1-480c-baf6-d8d9b09cd6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_acf_pacf(ts, nlags=40, figsize=(10, 5), \n",
    "                  annotate_sig=False, alpha=.05,\n",
    "                 acf_kws={}, pacf_kws={},  \n",
    "                  annotate_seas=False, m = None,\n",
    "                 seas_color='black'):\n",
    "    \n",
    "    fig, axes = plt.subplots(nrows=2, figsize=figsize)\n",
    "\n",
    "    \n",
    "    # Sig lags line style\n",
    "    sig_vline_kwargs = dict( ls=':', lw=1, zorder=0, color='red')\n",
    "\n",
    "    # ACF\n",
    "    tsa.graphics.plot_acf(ts, ax=axes[0], lags=nlags, **acf_kws)\n",
    "    \n",
    "    ## Annotating sig acf lags\n",
    "    if annotate_sig == True:\n",
    "        sig_acf_lags = get_sig_lags(ts,nlags=nlags,alpha=alpha, type='ACF')\n",
    "        for lag in sig_acf_lags:\n",
    "            axes[0].axvline(lag,label='sig', **sig_vline_kwargs )\n",
    "\n",
    "    # PACF\n",
    "    tsa.graphics.plot_pacf(ts,ax=axes[1], lags=nlags, **pacf_kws)\n",
    "    \n",
    "    ## Annotating sig pacf lags\n",
    "    if annotate_sig == True:\n",
    "        ## ANNOTATING SIG LAGS\n",
    "        sig_pacf_lags = get_sig_lags(ts,nlags=nlags,alpha=alpha, type='PACF')\n",
    "        for lag in sig_pacf_lags:\n",
    "            axes[1].axvline(lag, label='sig', **sig_vline_kwargs)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    ### ANNOTATE SEASONS\n",
    "    if annotate_seas == True:\n",
    "        # Ensure m was defined\n",
    "        if m is None:\n",
    "            raise Exception(\"Must define value of m if annotate_seas=True.\")\n",
    "\n",
    "        ## Calculate number of complete seasons to annotate\n",
    "        n_seasons = nlags//m \n",
    "\n",
    "        # Seasonal Lines style\n",
    "        seas_vline_kwargs = dict( ls='--',lw=1, alpha=.7, color=seas_color, zorder=-1)\n",
    "        \n",
    "        ## for each season, add a line\n",
    "        for i in range(1, n_seasons+1):\n",
    "            axes[0].axvline(m*i, **seas_vline_kwargs, label=\"season\")\n",
    "            axes[1].axvline(m*i, **seas_vline_kwargs, label=\"season\")\n",
    "\n",
    "    fig.tight_layout()\n",
    "    \n",
    "    return fig\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ca671b-cb4f-4b86-a6af-1498f10af08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from statsmodels\n",
    "â€‹â€‹import statsmodels.api as sm\n",
    "co2_data = sm.datasets.co2.load_pandas()\n",
    "df = co2_data.data\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f279d2-14da-400b-a969-10be76202a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute null values\n",
    "df['co2'] = df['co2'].interpolate()\n",
    "df.isna().sum().sum()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688ad28f-64cc-4504-89ce-e9b1163ccf3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample to monthly\n",
    "ts = df.resample(\"M\").mean()\n",
    "ts.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c77e660-1258-45d6-ae18-8c1923392551",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the series\n",
    "ts = ts['co2']\n",
    "# Plot\n",
    "ts.plot();\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc35c5a-9bb0-4688-be98-902de257c4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We see a repeating pattern that is likely seasonal\n",
    "# Apply seasonal decomposition\n",
    "decomp = tsa.seasonal_decompose(ts)\n",
    "fig = decomp.plot()\n",
    "fig.set_size_inches(12,5)\n",
    "fig.tight_layout()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ec0534-3044-4af0-bdf8-a456aaceb47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How big is the seasonal component\n",
    "seasonal_delta = decomp.seasonal.max() - decomp.seasonal.min()\n",
    "\n",
    "# How big is the seasonal component relative to the time series?\n",
    "print(f\"The seasonal component is {seasonal_delta} which is ~{seasonal_delta/(ts.max()-ts.min()) * 100 :.2f}% of the variation in time series.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04141611-88bc-49df-91a1-4b4eba36a36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Narrow down the date range of the plot\n",
    "seasonal = decomp.seasonal\n",
    "ax = seasonal.loc['1975': '1978'].plot(marker = 'o')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0def3d-26ed-405f-871b-f194c09f750b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine d\n",
    "d = ndiffs(ts)\n",
    "print (f'd = {d}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f739572-cf2b-4010-b533-f120e4b94715",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine D\n",
    "D = nsdiffs(ts, m =12)\n",
    "print(f'D = {D}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a416332-4ca0-494e-93b9-c8f021a4b198",
   "metadata": {},
   "outputs": [],
   "source": [
    "â€‹â€‹# Difference the data\n",
    "ts_diff = ts.diff().dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb1ee31-be0a-464a-8d1f-3c6195904101",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can use our function to highlight the seasonal lags by adding the arguments\n",
    "plot_acf_pacf(ts_diff, annotate_seas=True, m = 12);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0974cdce-3455-4177-bfcf-a6f3a802c225",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tts\n",
    "train, test = train_test_split(ts, test_size=.25)\n",
    "ax = train.plot(label='Train')\n",
    "test.plot(ax=ax, label='Test')\n",
    "ax.legend();\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877de069-624e-4f06-b3cf-fb6bff3c56f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Orders for non seasonal components\n",
    "p = 1  # nonseasonal AR\n",
    "d = 1  # nonseasonal differencing\n",
    "q = 1  # nonseasonal MA\n",
    "\n",
    "# Orders for seasonal components\n",
    "P = 1  # Seasonal AR\n",
    "D = 0  # Seasonal differencing\n",
    "Q = 1  # Seasonal MA\n",
    "m = 12 # Seasonal period\n",
    "\n",
    "sarima = tsa.ARIMA(train, order = (p,d,q), seasonal_order=(P,D,Q,m)).fit()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9682ef67-baae-4b88-b08a-384c92e70fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain summary of forecast as dataframe\n",
    "forecast_df = sarima.get_forecast(len(test)).summary_frame()\n",
    "# Plot the forecast with true values\n",
    "plot_forecast(train, test, forecast_df)\n",
    "# Obtain metrics\n",
    "regression_metrics_ts(test, forecast_df[\"mean\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c6a695-7946-419f-8de7-4fc0a951e6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain summary\n",
    "sarima.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd28f91-fbdb-42a3-9930-48ef41a0ae74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain diagnostic plots\n",
    "fig = sarima.plot_diagnostics()\n",
    "fig.set_size_inches(10,6)\n",
    "fig.tight_layout()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770c28a6-5e54-4bec-a337-40d83a9c3ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "# Define the value or range of values for p, d, q\n",
    "p_values = range(0, 3)  \n",
    "d_values = [1]          \n",
    "q_values = range(0, 3)  \n",
    "P_values = range (0, 3)\n",
    "D_values = [0]\n",
    "Q_values = range (0,3)\n",
    "m = [12]\n",
    "\n",
    "# Create combinations of pdq to test\n",
    "pdqPDQm_to_try = list(itertools.product(p_values, d_values, q_values, P_values, D_values, Q_values, m))\n",
    "\n",
    "# Display first 10 combinations\n",
    "pdqPDQm_to_try[:10]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34075f8b-5b8c-407e-8339-f117687e3d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define starting aic as infinity\n",
    "best_aic = float(\"inf\")  \n",
    "\n",
    "# define baseline for pdq\n",
    "best_pdqPDQm = (0,0,0,0,0,0,0)\n",
    "\n",
    "# Loop through each combination\n",
    "for pdqPDQm in pdqPDQm_to_try:\n",
    "    order = pdqPDQm[:3] # first three values are non seasonal (p,d,q)\n",
    "    seasonal_order = pdqPDQm[3:] # Remaining values for seasonal (P,D,Q,m)\n",
    "    \n",
    "    model = tsa.ARIMA(train, order=order, seasonal_order = seasonal_order)\n",
    "    try:                         \n",
    "        result = model.fit()\n",
    "        print(pdqPDQm, result.aic)      \n",
    "   \n",
    "    except:\n",
    "        print(f'{pdqPDQm}: caused an error')\n",
    "    \n",
    "    # If lower, replace best AIC with new value\n",
    "    if result.aic < best_aic:\n",
    "        \n",
    "        best_aic = result.aic\n",
    "        best_pdqPDQm = pdqPDQm\n",
    "\n",
    "# Print the best orders and AIC score\n",
    "print(\"Best AIC:\", best_aic)\n",
    "print(\"Best pdqPDQm:\", best_pdqPDQm)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dccdea9d-0816-41e9-8231-ad88349c852e",
   "metadata": {},
   "source": [
    "--------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726aaf86-f731-4322-98b5-f53006bdc8d2",
   "metadata": {},
   "source": [
    "# GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06af5e1-32f2-45f3-9baa-5b1d823cf252",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pmdarima as pm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd73f8c6-fbfa-4ad7-b80b-e45a5672ccb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import statsmodels.tsa.api as tsa\n",
    "from pmdarima.model_selection import train_test_split\n",
    "from pmdarima.arima.utils import ndiffs, nsdiffs\n",
    "\n",
    "# Set wide fig size for plots\n",
    "plt.rcParams['figure.figsize']=(12,3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a75459-df43-4b5e-a427-ef11bc15a782",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_forecast(ts_train, ts_test, forecast_df, n_train_lags=None, \n",
    "                  figsize=(10,4), title='Comparing Forecast vs. True Data'):\n",
    "    ### PLot training data, and forecast (with upper/,lower ci)\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "\n",
    "    # setting the number of train lags to plot if not specified\n",
    "    if n_train_lags==None:\n",
    "        n_train_lags = len(ts_train)\n",
    "            \n",
    "    # Plotting Training  and test data\n",
    "    ts_train.iloc[-n_train_lags:].plot(ax=ax, label=\"train\")\n",
    "    ts_test.plot(label=\"test\", ax=ax)\n",
    "\n",
    "    # Plot forecast\n",
    "    forecast_df['mean'].plot(ax=ax, color='green', label=\"forecast\")\n",
    "\n",
    "    # Add the shaded confidence interval\n",
    "    ax.fill_between(forecast_df.index, \n",
    "                    forecast_df['mean_ci_lower'],\n",
    "                   forecast_df['mean_ci_upper'],\n",
    "                   color='green', alpha=0.3,  lw=2)\n",
    "\n",
    "    # set the title and add legend\n",
    "    ax.set_title(title)\n",
    "    ax.legend();\n",
    "    \n",
    "    return fig, ax\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed9c62c-3b15-4498-9598-cabaabb8b062",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom function for Ad Fuller Test\n",
    "def get_adfuller_results(ts, alpha=.05, label='adfuller', **kwargs): #kwargs for adfuller()\n",
    "    # Saving each output\n",
    "    (test_stat, pval, nlags, nobs, crit_vals_d, \n",
    "    icbest ) = tsa.adfuller(ts, **kwargs)\n",
    "    # Converting output to a dictionary with the interpretation of p\n",
    "    adfuller_results = {'Test Statistic': test_stat,\n",
    "                        \"# of Lags Used\":nlags, \n",
    "                       '# of Observations':nobs,\n",
    "                        'p-value': round(pval,6),\n",
    "                        'alpha': alpha,\n",
    "                       'sig/stationary?': pval < alpha}\n",
    "    return pd.DataFrame(adfuller_results, index =[label])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058a314e-14fe-4389-9ccc-32980420ec71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, mean_absolute_percentage_error\n",
    "\n",
    "def regression_metrics_ts(ts_true, ts_pred, label=\"\", verbose=True, output_dict=False,):\n",
    "    # Get metrics\n",
    "    mae = mean_absolute_error(ts_true, ts_pred)\n",
    "    mse = mean_squared_error(ts_true, ts_pred)\n",
    "    rmse = mean_squared_error(ts_true, ts_pred, squared=False)\n",
    "    r_squared = r2_score(ts_true, ts_pred)\n",
    "    mae_perc = mean_absolute_percentage_error(ts_true, ts_pred) * 100\n",
    "\n",
    "    if verbose == True:\n",
    "        # Print Result with label\n",
    "        header = \"---\" * 20\n",
    "        print(header, f\"Regression Metrics: {label}\", header, sep=\"\\n\")\n",
    "        print(f\"- MAE = {mae:,.3f}\")\n",
    "        print(f\"- MSE = {mse:,.3f}\")\n",
    "        print(f\"- RMSE = {rmse:,.3f}\")\n",
    "        print(f\"- R^2 = {r_squared:,.3f}\")\n",
    "        print(f\"- MAPE = {mae_perc:,.2f}%\")\n",
    "\n",
    "    if output_dict == True:\n",
    "        metrics = {\n",
    "            \"Label\": label,\n",
    "            \"MAE\": mae,\n",
    "            \"MSE\": mse,\n",
    "            \"RMSE\": rmse,\n",
    "            \"R^2\": r_squared,\n",
    "            \"MAPE(%)\": mae_perc,\n",
    "        }\n",
    "        return metrics\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d58e1c3-6a02-4063-bbb8-8ec4e4a18926",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_acf_pacf(ts, nlags=40, figsize=(10, 5), \n",
    "                  annotate_sig=False, alpha=.05,\n",
    "                 acf_kws={}, pacf_kws={},  \n",
    "                  annotate_seas=False, m = None,\n",
    "                 seas_color='black'):\n",
    "    \n",
    "    fig, axes = plt.subplots(nrows=2, figsize=figsize)\n",
    "\n",
    "    \n",
    "    # Sig lags line style\n",
    "    sig_vline_kwargs = dict( ls=':', lw=1, zorder=0, color='red')\n",
    "\n",
    "    # ACF\n",
    "    tsa.graphics.plot_acf(ts, ax=axes[0], lags=nlags, **acf_kws)\n",
    "    \n",
    "    ## Annotating sig acf lags\n",
    "    if annotate_sig == True:\n",
    "        sig_acf_lags = get_sig_lags(ts,nlags=nlags,alpha=alpha, type='ACF')\n",
    "        for lag in sig_acf_lags:\n",
    "            axes[0].axvline(lag,label='sig', **sig_vline_kwargs )\n",
    "\n",
    "    # PACF\n",
    "    tsa.graphics.plot_pacf(ts,ax=axes[1], lags=nlags, **pacf_kws)\n",
    "    \n",
    "    ## Annotating sig pacf lags\n",
    "    if annotate_sig == True:\n",
    "        ## ANNOTATING SIG LAGS\n",
    "        sig_pacf_lags = get_sig_lags(ts,nlags=nlags,alpha=alpha, type='PACF')\n",
    "        for lag in sig_pacf_lags:\n",
    "            axes[1].axvline(lag, label='sig', **sig_vline_kwargs)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    ### ANNOTATE SEASONS\n",
    "    if annotate_seas == True:\n",
    "        # Ensure m was defined\n",
    "        if m is None:\n",
    "            raise Exception(\"Must define value of m if annotate_seas=True.\")\n",
    "\n",
    "        ## Calculate number of complete seasons to annotate\n",
    "        n_seasons = nlags//m \n",
    "\n",
    "        # Seasonal Lines style\n",
    "        seas_vline_kwargs = dict( ls='--',lw=1, alpha=.7, color=seas_color, zorder=-1)\n",
    "        \n",
    "        ## for each season, add a line\n",
    "        for i in range(1, n_seasons+1):\n",
    "            axes[0].axvline(m*i, **seas_vline_kwargs, label=\"season\")\n",
    "            axes[1].axvline(m*i, **seas_vline_kwargs, label=\"season\")\n",
    "\n",
    "    fig.tight_layout()\n",
    "    \n",
    "    return fig\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ce8fb5-2960-49d0-9e52-1d1565186bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Data/AirPassengers.csv')\n",
    "df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911c3847-ef62-479d-a47b-bbbf735a75a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the Month column to datetime\n",
    "df['Month'] = pd.to_datetime(df['Month'])\n",
    "# Set the Month column to the index\n",
    "df = df.set_index('Month')\n",
    "df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a331ab9-3630-4b43-9279-5cd917a74de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set frequency to first day of the month\n",
    "df = df.asfreq('MS')\n",
    "# Define the time series\n",
    "ts = df['#Passengers']\n",
    "ts.plot();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e549cc9-fb8e-4e1d-b81c-1f782ccb56f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply seasonal decomposition\n",
    "decomp = tsa.seasonal_decompose(ts)\n",
    "fig = decomp.plot()\n",
    "fig.set_size_inches(12,5)\n",
    "fig.tight_layout()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d29c28b-0868-43f9-a6ba-3bba2c1fc731",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How big is the seasonal component\n",
    "seasonal_delta = decomp.seasonal.max() - decomp.seasonal.min()\n",
    "\n",
    "# How big is the seasonal component relative to the time series?\n",
    "print(f\"The seasonal component is {seasonal_delta: .2f} which is ~{seasonal_delta/(ts.max()-ts.min()) * 100 :.2f}% of the variation in time series.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48279019-200e-4aa1-89ce-1decbee372f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Narrow down the date range of the plot\n",
    "seasonal = decomp.seasonal\n",
    "ax = seasonal.loc['1954': '1956'].plot(marker = 'o')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9fc7c6-25f6-494f-a651-b062835fc156",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for stationarity\n",
    "get_adfuller_results(ts)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a002f0-f5aa-4409-8be6-f1967f3d603f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine d\n",
    "d = ndiffs(ts)\n",
    "print (f'd = {d}')\n",
    "# determine D\n",
    "D = nsdiffs(ts, m = 12)\n",
    "print (f'D = {D}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd3307a-9594-420d-aafd-596916e69e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply both differencings\n",
    "ts_diff = ts.diff().diff(12).dropna()\n",
    "ts_diff.plot();\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69dfa904-bf2c-40b4-b02b-3969abf7f48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now look at the acf/pacf of the stationary data\n",
    "plot_acf_pacf(ts_diff, annotate_seas = True, m = 12, nlags = 60);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d568ff-1218-4758-91bc-3a07fb2d5595",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tts\n",
    "train, test = train_test_split(ts, test_size=.25)\n",
    "ax = train.plot(label='Train')\n",
    "test.plot(ax=ax, label='Test')\n",
    "ax.legend();\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb2344f-4906-450b-9803-ae261efe6719",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Orders for non seasonal components\n",
    "p = 1  # nonseasonal AR\n",
    "d = 1  # nonseasonal differencing\n",
    "q = 0  # nonseasonal MA\n",
    "\n",
    "# Orders for seasonal components\n",
    "P = 1  # Seasonal AR\n",
    "D = 1  # Seasonal differencing\n",
    "Q = 1  # Seasonal MA\n",
    "m = 12 # Seasonal period\n",
    "\n",
    "sarima = tsa.ARIMA(train, order = (p,d,q), seasonal_order=(P,D,Q,m)).fit()\n",
    "\n",
    "# Obtain summary\n",
    "sarima.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201a8f70-285c-4ccb-a703-188851bb9885",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain diagnostic plots\n",
    "fig = sarima.plot_diagnostics()\n",
    "fig.set_size_inches(10,6)\n",
    "fig.tight_layout()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40930442-f4bd-4250-8d81-f617a0fcc827",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain forecast as a dataframe with confidence intervals\n",
    "forecast_df = sarima.get_forecast(steps=len(test)).summary_frame()\n",
    "# Call the custom function to plot the forecasts with confidence intervals and true values\n",
    "plot_forecast(train, test, forecast_df);\n",
    "# Obtain metrics\n",
    "regression_metrics_ts(test, forecast_df['mean'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b95420e2-d337-4471-9d49-e0abde5560ae",
   "metadata": {},
   "source": [
    "## Auto_Arima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff38e03-043d-46e9-a410-004d654159d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pmdarima as pm\n",
    "\n",
    "# Default auto_arima will select model based on AIC score\n",
    "auto_model = pm.auto_arima(\n",
    "    train,\n",
    "    seasonal=True,  \n",
    "    m=12,\n",
    "    trace=True\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af8a09d-b22c-44d6-951d-c470c0a6c2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the auto_arima will store our best nonseasonal and seasonal orders separtely\n",
    "print(auto_model.order)\n",
    "print(auto_model.seasonal_order)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8cca2a-fba6-4962-b552-4bab18c29b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain summary of the best model from auto_arima\n",
    "auto_model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22252bf2-145b-4497-b540-038d40f266b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain diagnostic plots\n",
    "fig = auto_model.plot_diagnostics()\n",
    "fig.set_size_inches(10,6)\n",
    "fig.tight_layout()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e6dc91-9489-40c0-9556-1e275609bd7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use auto_arima parameters to fit an ARIMA\n",
    "auto_model = tsa.ARIMA(\n",
    "    train, order=auto_model.order, seasonal_order=auto_model.seasonal_order\n",
    ").fit()\n",
    "\n",
    "\n",
    "# Obtain forecast as a dataframe with confidence intervals\n",
    "forecast_df = auto_model.get_forecast(steps=len(test)).summary_frame()\n",
    "# Call the custom function to plot the forecasts with confidence intervals and true values\n",
    "plot_forecast(train, test, forecast_df);\n",
    "# Obtain metrics\n",
    "regression_metrics_ts(test, forecast_df['mean'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2eb14b3-d9cc-4825-b50a-c98577c79d3d",
   "metadata": {},
   "source": [
    "\r",
    "# \n",
    "Extracting Future Forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38acfdfd-0b75-408d-936f-ed29374948da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the parameters of our final model\n",
    "# Orders for non seasonal components\n",
    "p = 1  # nonseasonal AR\n",
    "d = 1  # nonseasonal differencing\n",
    "q = 0  # nonseasonal MA\n",
    "\n",
    "# Orders for seasonal components\n",
    "P = 0  # Seasonal AR\n",
    "D = 1  # Seasonal differencing\n",
    "Q = 0  # Seasonal MA\n",
    "m = 12 # Seasonal period\n",
    "\n",
    "final_model = tsa.ARIMA(ts, order = (p,d,q), seasonal_order=(P,D,Q,m)).fit()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94e8295-6b5c-40f2-b703-e1ebf0cec786",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8301a7d-0370-4867-b98c-7df1dd75936c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain future forecasts beyond test data\n",
    "forecast_df  = final_model.get_forecast(len(test)).summary_frame()\n",
    "plot_forecast(train,test,forecast_df);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9a9c10-fb59-4610-b106-549b3fd003d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_df.index[0],forecast_df.index[-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c733f8ea-ad84-4893-a059-7f837a6cffe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "starting_value = forecast_df['mean'].iloc[0]\n",
    "starting_value\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96bcc4f2-e85f-4f14-98bf-4462f69d7f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_value = forecast_df['mean'].iloc[-1]\n",
    "final_value\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40553e5-a561-4bed-b4fa-8cb78e246c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "change = final_value - starting_value\n",
    "change\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db85099-a88a-4514-874f-f39a1b04a7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "perc_change = (change / starting_value) * 100\n",
    "perc_change\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4405226-64c1-4650-8b71-0d0bfccc928c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cb0a59a1-3065-4b55-89ad-321d821bda6d",
   "metadata": {},
   "source": [
    "# Overall Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4570e14-538b-4613-ab14-3e2100a8c002",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.tsa.api as tsa\n",
    "â€‹import pmdarima as pm\n",
    "from pmdarima.arima.utils import ndiffs, nsdiffs\n",
    "â€‹from pmdarima.model_selection import train_test_split\n",
    "import pmdarima as pm\n",
    "â€‹plt.rcParams['figure.figsize']=(12,3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfed5b73-fdaa-48c4-b873-d791f150eac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load the data\n",
    "fname =''\n",
    "df = pd.read_csv(fname,\n",
    "                 # use args below if know datetime column already\n",
    "#                 parse_dates=[''], index_col=\"\" \n",
    "                )\n",
    "df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f8d3c2-944a-4296-a779-620399f79ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure index is datetime index\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0caba3-9843-455c-8c7f-4018a08117ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "â€‹# Select time series to model.\n",
    "col = '' # if a dataframe\n",
    "ts = df[col]\n",
    "ts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd63f031-2e81-4417-bf0a-a2b4890da68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "â€‹# check frequency\n",
    "ts.index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b3c361-4626-4d6e-a226-eb5df990dc4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resample to desired frequency\n",
    "# ts = ts.resample(...)..agg()\n",
    "# ts\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea50402-9082-47ad-abfd-4091dae18ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize selected time series\n",
    "ax = ts.plot()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4031376f-5ca1-4754-a6d8-dc9c8cd7a620",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for null values\n",
    "ts.isna().sum()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceef5f3e-2c59-41b6-be73-e1b57ee0ab8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Impute null values (if any)\n",
    "# ts = ts.fillna(0)\n",
    "# ts = ts.interpolate()\n",
    "# ts = ts.fillna(method='ffill')\n",
    "# ts = ts.fillna(method='bfill')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f605f1ad-c717-4321-80ca-fd4346f49257",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use Seasonal Decompose to check for seasonality\n",
    "decomp = tsa.seasonal_decompose(ts)\n",
    "fig = decomp.plot()\n",
    "fig.set_size_inches(9, 5)\n",
    "fig.tight_layout()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6038f2c7-3038-482d-a90c-e07154745e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How big is the seasonal component\n",
    "seasonal_delta = decomp.seasonal.max() - decomp.seasonal.min()\n",
    "\n",
    "# How big is the seasonal component relative to the time series?\n",
    "print(f\"The seasonal component is {seasonal_delta} which is ~{seasonal_delta/(ts.max()-ts.min()) * 100 :.2f}% of the variation in time series.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b59341c-b78e-45c4-8b75-87e2de9f8ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# zooming in on smaller time period to see length of season\n",
    "# decomp.seasonal.loc[\"...\":].plot();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048e93df-c242-4301-8ecf-9b38bca90c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for stationarity\n",
    "get_adfuller_results(ts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ee24f9-f750-4b90-a54d-cfd30ab7c257",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine differencing\n",
    "d = ndiffs(ts)\n",
    "print(f'd is {d}')\n",
    "D = nsdiffs(ts, m = _)\n",
    "print(f'D is {D}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6f67b6-3fbf-497a-a513-0c1edd484687",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For example, one non seasonal differencing\n",
    "â€‹ts_diff = ts.diff().dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a1ee35e-f917-4dbd-a6e2-7af38e55e426",
   "metadata": {},
   "outputs": [],
   "source": [
    "â€‹plot_acf_pacf(ts_diff, annotate_seas=True, m = _);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbb9eeb-41ef-4fe1-a311-3677294ab260",
   "metadata": {},
   "outputs": [],
   "source": [
    "â€‹from pmdarima.model_selection import train_test_split\n",
    "train, test = train_test_split(ts, test_size=___)\n",
    "â€‹\n",
    "â€‹## Visualize train-test-split\n",
    "ax = train.plot(label=\"train\")\n",
    "test.plot(label=\"test\")\n",
    "ax.legend();\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d53d3aa-0d5a-4c89-b09b-c5c5f0aaa567",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Orders for non seasonal components\n",
    "p = _  # nonseasonal AR\n",
    "d = _  # nonseasonal differencing\n",
    "q = _ # nonseasonal MA\n",
    "\n",
    "# Orders for seasonal components (if seasonal model)\n",
    "P = _  # Seasonal AR\n",
    "D = _  # Seasonal differencing\n",
    "Q = _  # Seasonal MA\n",
    "m = _ # Seasonal period\n",
    "\n",
    "sarima = tsa.ARIMA(train, order = (p,d,q), seasonal_order=(P,D,Q,m)).fit()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62895fd-ee9f-4d92-88dd-c72b97af1837",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain summary\n",
    "sarima.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb0167b-2f4d-40d6-8907-4b8fb82f109b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain diagnostic plots\n",
    "fig = sarima.plot_diagnostics()\n",
    "fig.set_size_inches(10,6)\n",
    "fig.tight_layout()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034c0922-7a39-4a3e-994a-e375d76b18cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain summary of forecast as dataframe\n",
    "forecast_df = sarima.get_forecast(len(test)).summary_frame()\n",
    "# Plot the forecast with true values\n",
    "plot_forecast(train, test, forecast_df, n_train_lags = 50)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f488114-ef39-4755-9f3a-8e97dc0c38fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_metrics_ts(test, forecast_df[\"forecast\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0dc7fd-b1e5-4615-9a58-9278ae18f94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pmdarima as pm\n",
    "# Default auto_arima will select model based on AIC score\n",
    "auto_model = pm.auto_arima(\n",
    "    train,\n",
    "    seasonal=___,  # True or False\n",
    "    m=____,  # if seasonal\n",
    "    trace=True\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb5a95d-c641-4d07-9858-319157cdb468",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try auto_arima orders\n",
    "sarima = tsa.ARIMA(train, order = auto_model.order, seasonal_order=auto_model.seasonal_order).fit()\n",
    "\n",
    "# Obtain summary\n",
    "sarima.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356e2503-e4d2-4e89-b895-1509262c1449",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_p = \"?\"\n",
    "final_q = \"?\"\n",
    "final_d = \"?\"\n",
    "final_P = \"?\"\n",
    "final_Q = \"?\"\n",
    "final_D = \"?\"\n",
    "â€‹\n",
    "â€‹final_model = tsa.ARIMA(\n",
    "    ts,\n",
    "    order=(final_p, final_d, final_q),\n",
    "    seasonal_order=(final_P, final_D, final_Q, m),\n",
    ").fit()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b1d852-fa1c-46b8-bf42-bdcd296323bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ger forecast into true future (fit on entrie time series)\n",
    "forecast_df = final_model.get_forecast(len(test)).summary_frame()\n",
    "\n",
    "plot_forecast(train, test, forecast_df, n_train_lags = 20);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91343d4d-0cb1-4756-9ed8-7e7a4a6a9cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define starting and final values\n",
    "starting_value = forecast_df['mean'].iloc[0]\n",
    "final_value = forecast_df['mean'].iloc[-1]\n",
    "# Change in x\n",
    "delta = final_value - starting_value\n",
    "print(f'The change in X over the forecast is {delta: .2f}.')\n",
    "perc_change = (delta/starting_value) *100\n",
    "print (f'The percentage change is {perc_change :.2f}%.')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f161cc-2792-40f9-8768-1958761969a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b415429-6bd9-4813-bdba-d923ae568b65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dojo-env)",
   "language": "python",
   "name": "dojo-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
